{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "X = np.array([1, 2, 3, 4,]).reshape(-1,1)\n",
    "# y=np.array([5, 6]).reshape(-1,1)\n",
    "y=np.array([5, 6, 7]).reshape(-1,1)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [6],\n",
       "       [7]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Forward Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers.InputLayer import InputLayer\n",
    "from Layers.FullyConnectedLayer import FullyConnectedLayer\n",
    "from Layers.TanhLayer import TanhLayer\n",
    "from Layers.LinearLayer import LinearLayer\n",
    "from LossFunctions.SquaredError import SquaredError\n",
    "\n",
    "# Create network\n",
    "IL = InputLayer(X)\n",
    "FCLU = FullyConnectedLayer(1, 5)\n",
    "ACT1 = TanhLayer()\n",
    "FCLW = FullyConnectedLayer(5, 5,)\n",
    "FCLV = FullyConnectedLayer(5, 3)\n",
    "ACT2 = LinearLayer()\n",
    "SE = SquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.34164079])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0\n",
    "IL_out = IL.forward(X[t])\n",
    "IL_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.92669485e-05, -1.21867223e-04,  1.03245534e-04,\n",
       "         3.23932314e-05,  1.02548688e-04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if t > 0:\n",
    "    FCLU_out = FCLU.forward_with_feedback(IL_out, FCLW.getPrevOut())\n",
    "else:\n",
    "    FCLU_out = FCLU.forward(IL_out)\n",
    "FCLU_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.92669484e-05, -1.21867222e-04,  1.03245534e-04,\n",
       "         3.23932314e-05,  1.02548687e-04]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT1_out = ACT1.forward(FCLU_out)\n",
    "ACT1_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.92669485e-05, -1.21867223e-04,  1.03245534e-04,\n",
       "          3.23932314e-05,  1.02548688e-04]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT1.getPrevIn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.92669484e-05, -1.21867222e-04,  1.03245534e-04,\n",
       "          3.23932314e-05,  1.02548687e-04]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT1.getPrevOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCLW (feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.68995420e-05,  3.73053684e-05,  6.69297594e-05,\n",
       "        -9.63355490e-05,  5.00559807e-05]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW_out = FCLW.forward(ACT1_out)\n",
    "FCLW_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.93402106e-05,  1.48180661e-05, -7.06538090e-05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV_out = FCLV.forward(ACT1_out)\n",
    "FCLV_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.92669484e-05, -1.21867222e-04,  1.03245534e-04,\n",
       "          3.23932314e-05,  1.02548687e-04]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.getPrevIn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACT2 - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.93402106e-05,  1.48180661e-05, -7.06538090e-05]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT2_out = ACT2.forward(FCLV_out)\n",
    "ACT2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.93402106e-05,  1.48180661e-05, -7.06538090e-05]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT2.getPrevIn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.93402106e-05,  1.48180661e-05, -7.06538090e-05]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT2.getPrevOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers.InputLayer import InputLayer\n",
    "from Layers.FullyConnectedLayer import FullyConnectedLayer\n",
    "from Layers.TanhLayer import TanhLayer\n",
    "from Layers.LinearLayer import LinearLayer\n",
    "from LossFunctions.SquaredError import SquaredError\n",
    "\n",
    "# Create network\n",
    "IL = InputLayer(X)\n",
    "FCLU = FullyConnectedLayer(1, 5)\n",
    "ACT1 = TanhLayer()\n",
    "FCLW = FullyConnectedLayer(5, 5,)\n",
    "FCLV = FullyConnectedLayer(5, 3)\n",
    "ACT2 = LinearLayer()\n",
    "SE = SquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.77261633e-05,  1.59506575e-05, -2.39590095e-05]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(4):\n",
    "    IL_out = IL.forward(X[t])\n",
    "\n",
    "    if t > 0:\n",
    "        FCLU_out = FCLU.forward_with_feedback(IL_out, FCLW.getPrevOut()[t-1])\n",
    "    else:\n",
    "        FCLU_out = FCLU.forward(IL_out)\n",
    "\n",
    "    ACT1_out = ACT1.forward(FCLU_out)\n",
    "\n",
    "    FCLW_out = FCLW.forward(ACT1_out)\n",
    "\n",
    "    FCLV_out = FCLV.forward(ACT1_out)\n",
    "\n",
    "    ACT2_out = ACT2.forward(FCLV_out)\n",
    "\n",
    "ACT2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.99990227],\n",
       "       [5.99998405],\n",
       "       [7.00002396]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y - ACT2_out.reshape(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.666388922329226"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE_out = SE.eval(y, ACT2_out.reshape(y.shape)) # Using only the last output from sequence to evaluate the loss\n",
    "SE_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Backward individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(X)-1, -1, -1):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.77261633e-05,  1.59506575e-05, -2.39590095e-05]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT2.getPrevOut()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop part 1: SE -> ACT 1 ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [6],\n",
       "       [7]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.93518549e-05, -8.68090426e-05,  5.11231601e-05]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACT2.getPrevOut()[-1] # Need to reshape..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.99980455, -11.9999681 , -14.00004792]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = SE.gradient(y, ACT2.getPrevOut()[-1].reshape(y.shape)).reshape(1, -1)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.99980455, -11.9999681 , -14.00004792]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = ACT2.backward(grad, t_inp=3) \n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Part 2: Update FCLV Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights grad accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00066809, -0.00080172, -0.00093535],\n",
       "       [-0.00032795, -0.00039354, -0.00045914],\n",
       "       [ 0.00053343,  0.00064013,  0.00074682],\n",
       "       [ 0.00078355,  0.00094027,  0.00109699],\n",
       "       [ 0.00072296,  0.00086756,  0.00101216]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.updateWeightsGradAccum(grad, t_inp=3)\n",
    "FCLV.weights_grad_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biases grad accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.biases_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.99980455, -11.9999681 , -14.00004792]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.updateBiasesGradAccum(grad)\n",
    "FCLV.biases_grad_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Part 3: Send backward through FCLV and ACT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhNext_dW = np.zeros((1, 5)) # Same shape as what FCLV.backward(grad) is...\n",
    "dhNext_dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.02192248e-04, -5.18354673e-05, -6.84714234e-05,\n",
       "         2.03300671e-03,  1.33489228e-04]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = FCLV.backward(grad) + dhNext_dW\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.02192244e-04, -5.18354673e-05, -6.84714232e-05,\n",
       "         2.03300670e-03,  1.33489227e-04]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = ACT1.backward(grad, t_inp=3)\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop part 4: Update FCLW gradients if t>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 3\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.biases_grad_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Looking at class notes): h2(t-1) is the t-1'th output of ACT1 i.e. the Tanh because Tanh is the previous input to FCLW - can use .backward() as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t > 0:\n",
    "    FCLW.updateWeightsGradAccum(grad, t_inp=t-1) # Have to use t-1\n",
    "    FCLW.updateBiasesGradAccum(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.92852571e-08, -1.10803470e-09, -1.46364482e-09,\n",
       "         4.34575414e-08,  2.85346508e-09],\n",
       "       [ 3.86887466e-08,  2.22286245e-09,  2.93626282e-09,\n",
       "        -8.71815087e-08, -5.72442394e-09],\n",
       "       [ 8.22609882e-08,  4.72630616e-09,  6.24315602e-09,\n",
       "        -1.85367521e-07, -1.21714145e-08],\n",
       "       [ 1.00709298e-08,  5.78625406e-10,  7.64328116e-10,\n",
       "        -2.26939080e-08, -1.49010441e-09],\n",
       "       [-1.22515120e-08, -7.03910781e-10, -9.29822292e-10,\n",
       "         2.76076479e-08,  1.81274542e-09]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.02192244e-04, -5.18354673e-05, -6.84714232e-05,\n",
       "         2.03300670e-03,  1.33489227e-04]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.biases_grad_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop part 5: Update FCLU gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU.biases_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.21041791e-03, -6.95445771e-05, -9.18640541e-05,\n",
       "         2.72756470e-03,  1.79094591e-04]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU.updateWeightsGradAccum(grad, t_inp=t)\n",
    "FCLU.weights_grad_accum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.02192244e-04, -5.18354673e-05, -6.84714232e-05,\n",
       "         2.03300670e-03,  1.33489227e-04]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU.updateBiasesGradAccum(grad)\n",
    "FCLU.biases_grad_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop part 6: Update dhNext_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.54249286e-08,  3.63345824e-08,  4.27520124e-08,\n",
       "        -1.20319617e-07, -1.63156032e-07]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dHnext_dW = FCLW.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.54249286e-08,  3.63345824e-08,  4.27520124e-08,\n",
       "        -1.20319617e-07, -1.63156032e-07]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dHnext_dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backwards Loop through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.02641757e-05, 4.06965304e-05, 2.20667899e-05]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Layers.InputLayer import InputLayer\n",
    "from Layers.FullyConnectedLayer import FullyConnectedLayer\n",
    "from Layers.TanhLayer import TanhLayer\n",
    "from Layers.LinearLayer import LinearLayer\n",
    "from LossFunctions.SquaredError import SquaredError\n",
    "\n",
    "# Create network\n",
    "IL = InputLayer(X)\n",
    "FCLU = FullyConnectedLayer(1, 5)\n",
    "ACT1 = TanhLayer()\n",
    "FCLW = FullyConnectedLayer(5, 5,)\n",
    "FCLV = FullyConnectedLayer(5, 3)\n",
    "ACT2 = LinearLayer()\n",
    "SE = SquaredError()\n",
    "\n",
    "for t in range(4):\n",
    "    IL_out = IL.forward(X[t])\n",
    "\n",
    "    if t > 0:\n",
    "        FCLU_out = FCLU.forward_with_feedback(IL_out, FCLW.getPrevOut()[t-1])\n",
    "    else:\n",
    "        FCLU_out = FCLU.forward(IL_out)\n",
    "\n",
    "    ACT1_out = ACT1.forward(FCLU_out)\n",
    "\n",
    "    FCLW_out = FCLW.forward(ACT1_out)\n",
    "\n",
    "    FCLV_out = FCLV.forward(ACT1_out)\n",
    "\n",
    "    ACT2_out = ACT2.forward(FCLV_out)\n",
    "\n",
    "ACT2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhNext_dW = np.zeros((1, 5)) # Same shape as what FCLV.backward(grad) is...\n",
    "\n",
    "# LOOP\n",
    "for t in range(len(X)-1, -1, -1):\n",
    "    grad = SE.gradient(y, ACT2.getPrevOut()[-1].reshape(y.shape)).reshape(1, -1)\n",
    "    grad = ACT2.backward(grad, t_inp=t)\n",
    "\n",
    "    FCLV.updateWeightsGradAccum(grad, t_inp=t)\n",
    "    FCLV.updateBiasesGradAccum(grad)\n",
    "\n",
    "    grad = FCLV.backward(grad) + dhNext_dW\n",
    "    grad = ACT1.backward(grad, t_inp=t)\n",
    "\n",
    "    if t > 0:\n",
    "        FCLW.updateWeightsGradAccum(grad, t_inp=t-1) # Have to use t-1\n",
    "        FCLW.updateBiasesGradAccum(grad)\n",
    "\n",
    "    FCLU.updateWeightsGradAccum(grad, t_inp=t)\n",
    "    FCLU.updateBiasesGradAccum(grad)\n",
    "\n",
    "    dHnext_dW = FCLW.backward(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.80232549e-06,  5.41767821e-05,  1.37715981e-05,\n",
       "        -6.85802428e-06, -3.14622184e-05]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanishing gradient issue - because gradient is multiplied by small numbers multiple times, becomes small\n",
    "Have to use a big learning rate to see a noticeable change in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.42938504e-12,  9.89638569e-12, -1.88404392e-11,\n",
       "        -7.04559328e-12,  2.94355230e-12]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.37294045e-06,  4.42803964e-05,  3.26120373e-05,\n",
       "         1.87568994e-07, -3.44057707e-05]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLU.updateWeights(grad, eta=1e6) # Note not actually using grad because it's just using its own accumulated gradient\n",
    "FCLU.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.10908920e-05,  5.03055634e-05, -5.55901720e-05],\n",
       "       [ 3.87036487e-06,  5.70592056e-05, -9.55339144e-05],\n",
       "       [-3.51275081e-05,  7.45844753e-05,  6.89419215e-05],\n",
       "       [ 7.68811852e-06,  7.33216548e-05,  8.99611983e-05],\n",
       "       [ 6.52813995e-05,  7.08230888e-05, -8.02513196e-05]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00359178,  0.00431013,  0.00502851],\n",
       "       [ 0.00306073,  0.00367288,  0.00428504],\n",
       "       [ 0.00263211,  0.00315854,  0.00368497],\n",
       "       [-0.00412656, -0.00495187, -0.00577721],\n",
       "       [ 0.00162161,  0.00194594,  0.00227027]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCLV.updateWeights(grad, eta=1e6) # Note not actually using grad because it's just using its own accumulated gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3591.77964978, -4310.13229805, -5028.50605066],\n",
       "       [-3060.73243145, -3672.87618441, -4285.03793351],\n",
       "       [-2632.11490608, -3158.53546506, -3684.97143845],\n",
       "       [ 4126.56454503,  4951.87390364,  5777.20719872],\n",
       "       [-1621.6147729 , -1945.93631461, -2270.26743849]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLV.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight change is pretty big for FCLV...maybe don't use a higher learning rate and accept FCLU weight may not change much?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCLW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.23717395e-05,  7.49923290e-05,  3.76826505e-05,\n",
       "         1.38988825e-05, -6.78057126e-05],\n",
       "       [-6.62399545e-06, -3.09655898e-05, -5.49920084e-05,\n",
       "         1.85023738e-05, -3.75460325e-05],\n",
       "       [ 8.32611107e-05,  8.19271050e-05, -4.85763412e-05,\n",
       "        -7.78217399e-05, -6.14074536e-05],\n",
       "       [-8.31658642e-08,  4.57171336e-05, -5.83611123e-05,\n",
       "        -5.03932883e-05,  7.03343750e-05],\n",
       "       [-1.68302563e-05,  2.33370134e-05, -5.32667722e-05,\n",
       "        -7.96065481e-05,  3.17140339e-06]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.42045543e-07, -1.67849229e-07,  4.12451974e-07,\n",
       "         6.05778804e-07,  1.03642397e-07],\n",
       "       [-2.52257088e-07, -1.74930541e-07,  4.29852715e-07,\n",
       "         6.31335720e-07,  1.08014918e-07],\n",
       "       [-1.96559883e-07, -1.36306682e-07,  3.34943213e-07,\n",
       "         4.91939697e-07,  8.41657208e-08],\n",
       "       [ 2.80256298e-07,  1.94346911e-07, -4.77564105e-07,\n",
       "        -7.01410663e-07, -1.20004005e-07],\n",
       "       [-7.71453777e-08, -5.34973380e-08,  1.31457753e-07,\n",
       "         1.93075378e-07,  3.30331713e-08]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24210791,  0.16792422, -0.41241429, -0.6057649 , -0.1037102 ],\n",
       "       [ 0.25225046,  0.17489958, -0.42990771, -0.63131722, -0.10805246],\n",
       "       [ 0.19664314,  0.13638861, -0.33499179, -0.49201752, -0.08422713],\n",
       "       [-0.28025638, -0.19430119,  0.47750574,  0.70136027,  0.12007434],\n",
       "       [ 0.07712855,  0.05352068, -0.13151102, -0.19315498, -0.03303   ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLW.updateWeights(grad, eta=1e6) # Note not actually using grad because it's just using its own accumulated gradient\n",
    "FCLW.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers.InputLayer import InputLayer\n",
    "from Layers.FullyConnectedLayer import FullyConnectedLayer\n",
    "from Layers.TanhLayer import TanhLayer\n",
    "from Layers.LinearLayer import LinearLayer\n",
    "from LossFunctions.SquaredError import SquaredError\n",
    "\n",
    "# Create network\n",
    "IL = InputLayer(X)\n",
    "FCLU = FullyConnectedLayer(1, 5)\n",
    "ACT1 = TanhLayer()\n",
    "FCLW = FullyConnectedLayer(5, 5,)\n",
    "FCLV = FullyConnectedLayer(5, 3)\n",
    "ACT2 = LinearLayer()\n",
    "SE = SquaredError()\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "eta = 0.001\n",
    "training_dict = {\"epoch\": list(range(epochs)),\n",
    "                 \"squared_error\": [],\n",
    "                 \"y_preds\": [],}\n",
    "\n",
    "\n",
    "#TODO: Loop outputs can be more efficient. Keeping explicit as separate variables for tracking purposes\n",
    "for epoch in range(epochs):\n",
    "    # Forward\n",
    "    for t in range(len(X)):\n",
    "        IL_out = IL.forward(X[t])\n",
    "        if t > 0:\n",
    "            FCLU_out = FCLU.forward_with_feedback(IL_out, FCLW.getPrevOut()[t-1])\n",
    "        else:\n",
    "            FCLU_out = FCLU.forward(IL_out)\n",
    "        ACT1_out = ACT1.forward(FCLU_out)\n",
    "        FCLW_out = FCLW.forward(ACT1_out)\n",
    "        FCLV_out = FCLV.forward(ACT1_out)\n",
    "        ACT2_out = ACT2.forward(FCLV_out)\n",
    "\n",
    "    # Predictions and Loss\n",
    "    # training_dict[\"y_preds\"].append(ACT2_out.reshape(y.shape))\n",
    "    training_dict[\"y_preds\"].append(ACT2_out)\n",
    "\n",
    "    error = SE.eval(y, ACT2_out.reshape(y.shape))\n",
    "    training_dict[\"squared_error\"].append(error)\n",
    "\n",
    "    # Backward\n",
    "    dhNext_dW = np.zeros((1, 5)) # Same shape as what FCLV.backward(grad) is...\n",
    "    for t in range(len(X)-1, -1, -1):\n",
    "        grad = SE.gradient(y, ACT2.getPrevOut()[-1].reshape(y.shape)).reshape(1, -1)\n",
    "        grad = ACT2.backward(grad, t_inp=t)\n",
    "\n",
    "        FCLV.updateWeightsGradAccum(grad, t_inp=t)\n",
    "        FCLV.updateBiasesGradAccum(grad)\n",
    "\n",
    "        grad = FCLV.backward(grad) + dhNext_dW\n",
    "        grad = ACT1.backward(grad, t_inp=t)\n",
    "\n",
    "        if t > 0:\n",
    "            FCLW.updateWeightsGradAccum(grad, t_inp=t-1) # Have to use t-1\n",
    "            FCLW.updateBiasesGradAccum(grad)\n",
    "\n",
    "        FCLU.updateWeightsGradAccum(grad, t_inp=t)\n",
    "        FCLU.updateBiasesGradAccum(grad)\n",
    "\n",
    "        dHnext_dW = FCLW.backward(grad)\n",
    "\n",
    "    # Update weights   \n",
    "    FCLU.updateWeights(grad, eta=eta)\n",
    "    FCLV.updateWeights(grad, eta=eta)\n",
    "    FCLW.updateWeights(grad, eta=eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>squared_error</th>\n",
       "      <th>y_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36.666627</td>\n",
       "      <td>[[1.2099250201445788e-05, 3.433328095955348e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>36.082307</td>\n",
       "      <td>[[0.040012003668248274, 0.04803406016236948, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.932329</td>\n",
       "      <td>[[0.11969181340112009, 0.1436495164123391, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33.253419</td>\n",
       "      <td>[[0.23841409029439736, 0.2861157790482189, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31.099193</td>\n",
       "      <td>[[0.39522905675714043, 0.4742931191168578, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>28.538449</td>\n",
       "      <td>[[0.5888821941252298, 0.7066761196742304, 0.82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>25.652967</td>\n",
       "      <td>[[0.8178242789628763, 0.981405719274073, 1.144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>22.534898</td>\n",
       "      <td>[[1.080223776984037, 1.2962840845852528, 1.512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>19.283820</td>\n",
       "      <td>[[1.3739814954129514, 1.6487921931228848, 1.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>16.003561</td>\n",
       "      <td>[[1.696747376536892, 2.0361099853991256, 2.375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>12.798877</td>\n",
       "      <td>[[2.045939298079014, 2.455138925249528, 2.8642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>9.772115</td>\n",
       "      <td>[[2.4187637299716775, 2.9025267878339456, 3.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>7.019936</td>\n",
       "      <td>[[2.812238082268671, 3.3746944770007006, 3.937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>4.630235</td>\n",
       "      <td>[[3.2232145654164754, 3.867864657480781, 4.512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2.679328</td>\n",
       "      <td>[[3.648405372017417, 4.37809197287395, 5.10775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.229521</td>\n",
       "      <td>[[4.084408978656973, 4.901294607715865, 5.7181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.327115</td>\n",
       "      <td>[[4.527737357417292, 5.433286941174759, 6.3388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>[[4.9748438794297805, 5.969813031202973, 6.964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.261379</td>\n",
       "      <td>[[5.422151687288807, 6.506580661331316, 7.5910...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.100149</td>\n",
       "      <td>[[5.8660823093999, 7.039295677795489, 8.212523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2.490452</td>\n",
       "      <td>[[6.303084287398793, 7.563696342358954, 8.8243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>4.387887</td>\n",
       "      <td>[[6.72966158766776, 8.075587426064427, 9.42154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>6.731857</td>\n",
       "      <td>[[7.142401569693913, 8.570873771207575, 9.9993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>9.447505</td>\n",
       "      <td>[[7.538002287547183, 9.045593053065863, 10.553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>12.448103</td>\n",
       "      <td>[[7.913298906076003, 9.49594747929944, 11.0786...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>15.637825</td>\n",
       "      <td>[[8.265289020484573, 9.918334173419721, 11.571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>18.914801</td>\n",
       "      <td>[[8.591156676711522, 10.309373999228177, 12.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>22.174378</td>\n",
       "      <td>[[8.888294900406793, 10.665938595580037, 12.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>25.312458</td>\n",
       "      <td>[[9.154326554219885, 10.985175405127048, 12.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>28.228820</td>\n",
       "      <td>[[9.387123356473705, 11.264530496726646, 13.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>30.830328</td>\n",
       "      <td>[[9.584822908998346, 11.501768998845087, 13.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>33.033900</td>\n",
       "      <td>[[9.745843597821178, 11.694992980388452, 13.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>34.769161</td>\n",
       "      <td>[[9.868897247426663, 11.842656635816102, 13.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>35.980693</td>\n",
       "      <td>[[9.95299942727536, 11.943578652962582, 13.934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>36.629805</td>\n",
       "      <td>[[9.99747732806272, 11.996951664543522, 13.996...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>36.695768</td>\n",
       "      <td>[[10.001975144653514, 12.002348707667712, 14.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>36.176474</td>\n",
       "      <td>[[9.966456922591068, 11.959726639633717, 13.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>35.088509</td>\n",
       "      <td>[[9.891206845390712, 11.869426482662197, 13.84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>33.466619</td>\n",
       "      <td>[[9.776826960321086, 11.732170694808312, 13.68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>31.362602</td>\n",
       "      <td>[[9.624232360889305, 11.549057388913944, 13.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>28.843651</td>\n",
       "      <td>[[9.434643864611834, 11.321551545898703, 13.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>25.990214</td>\n",
       "      <td>[[9.20957824470765, 11.051473292754759, 12.893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>22.893418</td>\n",
       "      <td>[[8.950836093932853, 10.740983339109837, 12.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>19.652164</td>\n",
       "      <td>[[8.660487417728579, 10.392565688966252, 12.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>16.369964</td>\n",
       "      <td>[[8.34085507202487, 10.009007766028997, 11.677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>13.151638</td>\n",
       "      <td>[[7.994496178286472, 9.5933781117279, 11.19231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>10.099968</td>\n",
       "      <td>[[7.624181664564247, 9.149001834452346, 10.673...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>7.312409</td>\n",
       "      <td>[[7.232874096299293, 8.679434006496988, 10.126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>4.877984</td>\n",
       "      <td>[[6.823703974296377, 8.188431221620295, 9.5531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2.874438</td>\n",
       "      <td>[[6.399944689530649, 7.67992154081438, 8.95993...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  squared_error                                            y_preds\n",
       "0       0      36.666627  [[1.2099250201445788e-05, 3.433328095955348e-0...\n",
       "1       1      36.082307  [[0.040012003668248274, 0.04803406016236948, 0...\n",
       "2       2      34.932329  [[0.11969181340112009, 0.1436495164123391, 0.1...\n",
       "3       3      33.253419  [[0.23841409029439736, 0.2861157790482189, 0.3...\n",
       "4       4      31.099193  [[0.39522905675714043, 0.4742931191168578, 0.5...\n",
       "5       5      28.538449  [[0.5888821941252298, 0.7066761196742304, 0.82...\n",
       "6       6      25.652967  [[0.8178242789628763, 0.981405719274073, 1.144...\n",
       "7       7      22.534898  [[1.080223776984037, 1.2962840845852528, 1.512...\n",
       "8       8      19.283820  [[1.3739814954129514, 1.6487921931228848, 1.92...\n",
       "9       9      16.003561  [[1.696747376536892, 2.0361099853991256, 2.375...\n",
       "10     10      12.798877  [[2.045939298079014, 2.455138925249528, 2.8642...\n",
       "11     11       9.772115  [[2.4187637299716775, 2.9025267878339456, 3.38...\n",
       "12     12       7.019936  [[2.812238082268671, 3.3746944770007006, 3.937...\n",
       "13     13       4.630235  [[3.2232145654164754, 3.867864657480781, 4.512...\n",
       "14     14       2.679328  [[3.648405372017417, 4.37809197287395, 5.10775...\n",
       "15     15       1.229521  [[4.084408978656973, 4.901294607715865, 5.7181...\n",
       "16     16       0.327115  [[4.527737357417292, 5.433286941174759, 6.3388...\n",
       "17     17       0.000928  [[4.9748438794297805, 5.969813031202973, 6.964...\n",
       "18     18       0.261379  [[5.422151687288807, 6.506580661331316, 7.5910...\n",
       "19     19       1.100149  [[5.8660823093999, 7.039295677795489, 8.212523...\n",
       "20     20       2.490452  [[6.303084287398793, 7.563696342358954, 8.8243...\n",
       "21     21       4.387887  [[6.72966158766776, 8.075587426064427, 9.42154...\n",
       "22     22       6.731857  [[7.142401569693913, 8.570873771207575, 9.9993...\n",
       "23     23       9.447505  [[7.538002287547183, 9.045593053065863, 10.553...\n",
       "24     24      12.448103  [[7.913298906076003, 9.49594747929944, 11.0786...\n",
       "25     25      15.637825  [[8.265289020484573, 9.918334173419721, 11.571...\n",
       "26     26      18.914801  [[8.591156676711522, 10.309373999228177, 12.02...\n",
       "27     27      22.174378  [[8.888294900406793, 10.665938595580037, 12.44...\n",
       "28     28      25.312458  [[9.154326554219885, 10.985175405127048, 12.81...\n",
       "29     29      28.228820  [[9.387123356473705, 11.264530496726646, 13.14...\n",
       "30     30      30.830328  [[9.584822908998346, 11.501768998845087, 13.41...\n",
       "31     31      33.033900  [[9.745843597821178, 11.694992980388452, 13.64...\n",
       "32     32      34.769161  [[9.868897247426663, 11.842656635816102, 13.81...\n",
       "33     33      35.980693  [[9.95299942727536, 11.943578652962582, 13.934...\n",
       "34     34      36.629805  [[9.99747732806272, 11.996951664543522, 13.996...\n",
       "35     35      36.695768  [[10.001975144653514, 12.002348707667712, 14.0...\n",
       "36     36      36.176474  [[9.966456922591068, 11.959726639633717, 13.95...\n",
       "37     37      35.088509  [[9.891206845390712, 11.869426482662197, 13.84...\n",
       "38     38      33.466619  [[9.776826960321086, 11.732170694808312, 13.68...\n",
       "39     39      31.362602  [[9.624232360889305, 11.549057388913944, 13.47...\n",
       "40     40      28.843651  [[9.434643864611834, 11.321551545898703, 13.20...\n",
       "41     41      25.990214  [[9.20957824470765, 11.051473292754759, 12.893...\n",
       "42     42      22.893418  [[8.950836093932853, 10.740983339109837, 12.53...\n",
       "43     43      19.652164  [[8.660487417728579, 10.392565688966252, 12.12...\n",
       "44     44      16.369964  [[8.34085507202487, 10.009007766028997, 11.677...\n",
       "45     45      13.151638  [[7.994496178286472, 9.5933781117279, 11.19231...\n",
       "46     46      10.099968  [[7.624181664564247, 9.149001834452346, 10.673...\n",
       "47     47       7.312409  [[7.232874096299293, 8.679434006496988, 10.126...\n",
       "48     48       4.877984  [[6.823703974296377, 8.188431221620295, 9.5531...\n",
       "49     49       2.874438  [[6.399944689530649, 7.67992154081438, 8.95993..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(training_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.97484388, 5.96981303, 6.96478134]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y_preds\"].loc[17] # where min is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='epoch'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x=\"epoch\", y=\"squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error reaches a minimum then goes back?\n",
    "* Wonder if it has to do with one of the layers' weights not changing enough due to vanishing gradients\n",
    "* Is the tanh doing something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 1.20992502e-05,  3.43332810e-05, -2.94946189e-05]]),\n",
       "       array([[1.69674738, 2.03610999, 2.37541567]]),\n",
       "       array([[4.97484388, 5.96981303, 6.96478134]])], dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_index_lst = [0, 9, 17]\n",
    "y_preds_graph = df[\"y_preds\"].loc[graph_index_lst].to_numpy()\n",
    "y_preds_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [137], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_preds_graph\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "X = X.astype(float)\n",
    "np.concatenate(X.flatten(), y_preds_graph[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
